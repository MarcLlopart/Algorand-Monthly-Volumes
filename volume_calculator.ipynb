{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "import requests\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "MONTH_DIR = 'Jan 2025'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stables\n",
    "# 31566704 USDC\n",
    "# 312769 USDT \n",
    "# 227855942 EURS\n",
    "# 760037151 xUSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv(coin_id, currency):\n",
    "    \"\"\"\n",
    "    This function downloads the data from Coingecko with the usd pair.\n",
    "    Inputs:\n",
    "        - coin_id: the name of the crypto we are getting the data\n",
    "        - currency: by default it is the usd\n",
    "    Output:\n",
    "        - This function simply stores under raw_data directory a file\n",
    "        from coingecko with all historic data available\n",
    "    \"\"\"\n",
    "    # Construct the URL\n",
    "    base_url = \"https://www.coingecko.com\"\n",
    "    csv_path = f\"/price_charts/export/{coin_id}/{currency}.csv\"\n",
    "    full_url = base_url + csv_path\n",
    "\n",
    "    # Download the CSV\n",
    "    response = requests.get(full_url)\n",
    "    if response.status_code == 200:\n",
    "        file_name = f\"{MONTH_DIR}/{coin_id}_historical_data.csv\"\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download CSV for {coin_id}.\")\n",
    "\n",
    "download_csv('algorand', 'usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_unix_timestamp(start_date_str, end_date_str):\n",
    "  \"\"\"\n",
    "  Converts start and end dates in YYYY-MM-DD format to Unix timestamps.\n",
    "\n",
    "  Args:\n",
    "    start_date_str: Start date string in YYYY-MM-DD format.\n",
    "    end_date_str: End date string in YYYY-MM-DD format.\n",
    "\n",
    "  Returns:\n",
    "    A tuple containing the start and end Unix timestamps.\n",
    "  \"\"\"\n",
    "\n",
    "  start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "  end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(tzinfo=timezone.utc) + timedelta(days=1) - timedelta(seconds=1) \n",
    "\n",
    "  start_timestamp = int(start_date.timestamp())\n",
    "  end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "  return start_timestamp, end_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_price(start_date, end_date, asset_id):\n",
    "    \"\"\"\n",
    "    Fetches an asset historical data from the API for the given interval.\n",
    "    \n",
    "    Args:\n",
    "        start_timestamp: start unix timestamp\n",
    "        end_timestamp: end unix timestamp\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing the fetched data in daily intervals.\n",
    "    \"\"\"\n",
    "    start_unix, end_unix = date_to_unix_timestamp(start_date, end_date)\n",
    "\n",
    "    price_feed = f'https://indexer.vestige.fi/assets/{asset_id}/candles?network_id=0&interval=86400&start={start_unix}&end={end_unix}&denominating_asset_id=0&volume_in_denominating_asset=false'\n",
    "\n",
    "    response = requests.get(price_feed)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2025-01-01'\n",
    "end_date = '2025-12-31'\n",
    "\n",
    "stables_dfs = {}\n",
    "stables_ids = {'usdc': 31566704, 'usdt': 312769,\n",
    "              'eurs': 227855942,'xusd':760037151}\n",
    "\n",
    "for stablecoin, stables_id in stables_ids.items():\n",
    "    stables_dfs[stablecoin] = get_close_price(start_date, end_date, stables_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2025-01-01'\n",
    "end_date = '2025-01-31'\n",
    "\n",
    "asas_dfs = {}\n",
    "asas_ids = {\n",
    "            'ora': 1284444444, 'monko': 2494786278, 'niko': 1265975021, 'ballsack': 2656692124, \n",
    "            'tiny': 2200000000, 'mooj': 2154668640, 'gobtc': 386192725, 'vote': 452399768, \n",
    "            'xalgo': 1134696561, 'opul': 287867876, 'talgo': 2537013734, 'coop': 796425061, \n",
    "            'bro': 2637100337, 'galgo': 793124631, 'ipt': 2342621554, 'gold': 246516580, \n",
    "            'avoi': 2320775407, 'goeth': 386195940, 'meep': 2582590415, 'cat': 1691166331\n",
    "        }\n",
    "\n",
    "for asa, asa_id in asas_ids.items():\n",
    "    asas_dfs[asa] = get_close_price(start_date, end_date, asa_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_df(dataframes):\n",
    "  \"\"\"\n",
    "  Creates a single DataFrame with 'date' as the index and \n",
    "  'close' columns named after the stablecoin keys.\n",
    "\n",
    "  Args:\n",
    "    dataframes: A dictionary where keys are stablecoin names \n",
    "                and values are the corresponding DataFrames.\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame with the combined data.\n",
    "  \"\"\"\n",
    "\n",
    "  combined_df = pd.DataFrame()\n",
    "\n",
    "  for asset, df in dataframes.items():\n",
    "    df['date'] = pd.to_datetime(df['timestamp'], unit='s') \n",
    "    df.set_index('date', inplace=True) \n",
    "    df.rename(columns={'close': asset}, inplace=True) \n",
    "    combined_df = combined_df.join(df[asset], how='outer') \n",
    "\n",
    "  return combined_df\n",
    "\n",
    "# Example usage\n",
    "stables_final_df = create_combined_df(stables_dfs) \n",
    "asas_final_df = create_combined_df(asas_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stables_final_df.to_csv(f'{MONTH_DIR}/Results/stablecoins_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "asas_final_df.to_csv(f'{MONTH_DIR}/Results/asas_jan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_price = pd.read_csv(f'{MONTH_DIR}/algorand_historical_data.csv')\n",
    "algo_price['snapped_at'] = pd.to_datetime(algo_price['snapped_at'])\n",
    "price_feed = algo_price[(algo_price['snapped_at'] >= start_date) & (algo_price['snapped_at'] <= end_date)]\n",
    "price_feed[['snapped_at', 'price']].to_csv(f'{MONTH_DIR}/Results/ALGO_dec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ora', 'monko', 'niko', 'ballsack', 'tiny', 'mooj', 'gobtc',\n",
       "       'vote', 'xalgo', 'opul', 'talgo', 'coop', 'bro', 'galgo', 'ipt',\n",
       "       'gold', 'avoi', 'goeth', 'meep', 'cat'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asa_volumes = pd.read_csv(f'{MONTH_DIR}/asa_volumes.csv')\n",
    "asa_volumes['dt'] = pd.to_datetime(asa_volumes['dt'])\n",
    "asa_volumes.columns.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "asa_volumes = pd.read_csv(f'{MONTH_DIR}/asa_volumes.csv')\n",
    "asa_volumes['dt'] = pd.to_datetime(asa_volumes['dt'])\n",
    "\n",
    "\n",
    "def multiply_columns(df1, df2):\n",
    "  \"\"\"\n",
    "  Joins price and volume dataframes to convert into ALGO volumes\n",
    "\n",
    "  Args:\n",
    "    df1: Volumes Dataframe in native Currency\n",
    "    df2: Asset/ALGO Price DataFrame.\n",
    "\n",
    "  Returns:\n",
    "    A merged DataFrame with ALGO Volumes\n",
    "  \"\"\"\n",
    "\n",
    "  # Merge DataFrames on 'dt' and 'date'\n",
    "  merged_df = df1.merge(df2, left_on='dt', right_on='date', suffixes=('_df1', '_df2'))\n",
    "\n",
    "  # Calculate product of corresponding columns\n",
    "  columns_to_multiply = df1.columns.values[1:]\n",
    "  for col in columns_to_multiply:\n",
    "      merged_df[col] = merged_df[col + '_df1'] * merged_df[col + '_df2']\n",
    "\n",
    "  # Drop unnecessary columns\n",
    "  merged_df.drop(columns=[col + '_df1' for col in columns_to_multiply] + \n",
    "                  [col + '_df2' for col in columns_to_multiply], \n",
    "             inplace=True)\n",
    "\n",
    "  # Rename 'dt' column to 'date'\n",
    "  merged_df.rename(columns={'dt': 'date'}, inplace=True)\n",
    "\n",
    "  return merged_df\n",
    "\n",
    "\n",
    "result_df = multiply_columns(asa_volumes, asas_final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_merge(algo_volumes, algo_price):\n",
    "  \"\"\"\n",
    "  Joins volumes and algo price dataframes to convert into USD volume\n",
    "\n",
    "  Args:\n",
    "    df1: Volumes Dataframe in ALGO\n",
    "    df2: ALGO/USD Price DataFrame.\n",
    "\n",
    "  Returns:\n",
    "    A merged DataFrame with ALGO Volumes\n",
    "  \"\"\"\n",
    "\n",
    "    # Merge DataFrames on 'dt' and 'date'\n",
    "  merged_df = algo_volumes.merge(algo_price[['snapped_at', 'price']], left_on='date', right_on='snapped_at')\n",
    "\n",
    "  merged_df.drop('snapped_at', axis=1, inplace=True)\n",
    "  # Calculate product of corresponding columns\n",
    "  merged_df['usd_vol'] = merged_df['algo_vol']*merged_df['price']\n",
    "\n",
    "  # Rename 'dt' column to 'date'\n",
    "  #merged_df.rename(columns={'dt': 'date'}, inplace=True)\n",
    "\n",
    "  return merged_df\n",
    "\n",
    "\n",
    "stables = pd.read_csv(f'{MONTH_DIR}/stables.csv')\n",
    "algorand = pd.read_csv(f'{MONTH_DIR}/algorand_historical_data.csv')\n",
    "\n",
    "stables['dt'] = pd.to_datetime(stables['dt'])\n",
    "algorand['snapped_at'] = pd.to_datetime(algorand['snapped_at']).dt.date\n",
    "\n",
    "result_df = multiply_columns(stables, stables_final_df)\n",
    "result_df['algo_vol'] = result_df[result_df.columns.values[1:]].sum(axis=1)\n",
    "\n",
    "result_df['date'] = pd.to_datetime(result_df['date']).dt.date\n",
    "\n",
    "usd = price_merge(result_df, algorand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{MONTH_DIR}/Results/asas_algo_volumes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# HAFN\n",
    "\n",
    "def get_price_feed(ticker):\n",
    "  \"\"\"\n",
    "  Fetches the price feed for the specified ticker for December 2024 \n",
    "  using the yfinance library.\n",
    "\n",
    "  Args:\n",
    "    ticker: The ticker symbol (e.g., \"AFNUSD=X\").\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame containing the historical data for the specified period.\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    # Define start and end dates, consider forex does not operate 24/7\n",
    "    start_date = \"2025-01-01\"\n",
    "    end_date = \"2025-01-31\"\n",
    "\n",
    "    # Download historical data using yfinance\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data\n",
    "  except Exception as e:\n",
    "    print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "ticker = \"AFNUSD=X\"\n",
    "december_data = get_price_feed(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "december_data.to_csv(f'{MONTH_DIR}/Results/HAFN_dec.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
